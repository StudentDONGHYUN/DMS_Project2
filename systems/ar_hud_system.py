"""
S-Class DMS v19.0 - ìƒí™©ì¸ì§€í˜• ì¦ê°•í˜„ì‹¤ HUD ì‹œìŠ¤í…œ
ì „ë©´ ìœ ë¦¬ì— ì§ì ‘ ì •ë³´ë¥¼ íˆ¬ì‚¬í•˜ëŠ” ì§€ëŠ¥í˜• AR ì¸í„°í˜ì´ìŠ¤
"""

import asyncio
import time
import numpy as np
import json
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, field
from enum import Enum
from collections import deque
from pathlib import Path
import math
import cv2

from config.settings import get_config
from models.data_structures import UIState, GazeData


class ARObjectType(Enum):
    """AR ê°ì²´ ìœ í˜•"""

    WARNING_BOX = "warning_box"
    NAVIGATION_ARROW = "navigation_arrow"
    LANE_HIGHLIGHT = "lane_highlight"
    VEHICLE_INFO = "vehicle_info"
    SPEED_LIMIT = "speed_limit"
    DISTANCE_INDICATOR = "distance_indicator"
    HAZARD_MARKER = "hazard_marker"
    BLIND_SPOT_ALERT = "blind_spot_alert"
    PARKING_GUIDE = "parking_guide"
    BIOMETRIC_OVERLAY = "biometric_overlay"


class ARPriority(Enum):
    """AR í‘œì‹œ ìš°ì„ ìˆœìœ„"""

    CRITICAL = 1  # ì¦‰ì‹œ ìœ„í—˜ (ë¹¨ê°„ìƒ‰)
    HIGH = 2  # ë†’ì€ ìœ„í—˜ (ì£¼í™©ìƒ‰)
    MEDIUM = 3  # ì£¼ì˜ í•„ìš” (ë…¸ë€ìƒ‰)
    LOW = 4  # ì¼ë°˜ ì •ë³´ (íŒŒë€ìƒ‰)
    INFO = 5  # ì°¸ê³  ì •ë³´ (íšŒìƒ‰)


class GazeRegion(Enum):
    """ì‹œì„  ì˜ì—­"""

    CENTER = "center"  # ì¤‘ì•™ (ì „ë°©)
    LEFT_MIRROR = "left_mirror"  # ì¢Œì¸¡ ë¯¸ëŸ¬
    RIGHT_MIRROR = "right_mirror"  # ìš°ì¸¡ ë¯¸ëŸ¬
    REAR_MIRROR = "rear_mirror"  # í›„ë°© ë¯¸ëŸ¬
    DASHBOARD = "dashboard"  # ëŒ€ì‹œë³´ë“œ
    LEFT_BLIND = "left_blind"  # ì¢Œì¸¡ ì‚¬ê°ì§€ëŒ€
    RIGHT_BLIND = "right_blind"  # ìš°ì¸¡ ì‚¬ê°ì§€ëŒ€


@dataclass
class ARObject:
    """AR ê°ì²´"""

    object_id: str
    object_type: ARObjectType
    priority: ARPriority

    # 3D ìœ„ì¹˜ (ì›”ë“œ ì¢Œí‘œ)
    world_position: Tuple[float, float, float]  # (x, y, z)

    # 2D í™”ë©´ ìœ„ì¹˜ (í”½ì…€ ì¢Œí‘œ)
    screen_position: Tuple[int, int]  # (x, y)

    # ì‹œê°ì  ì†ì„±
    size: Tuple[int, int]  # (width, height)
    color: Tuple[int, int, int, int]  # RGBA
    thickness: int = 2

    # ë‚´ìš©
    text: Optional[str] = None
    icon: Optional[str] = None

    # ë™ì‘
    blink_rate: float = 0.0  # ê¹œë¹¡ì„ ì£¼ê¸° (0 = ê³ ì •)
    fade_duration: float = 0.0  # í˜ì´ë“œ ì§€ì†ì‹œê°„ (0 = ì˜êµ¬)

    # ìƒíƒœ
    is_visible: bool = True
    created_at: float = field(default_factory=time.time)
    last_updated: float = field(default_factory=time.time)

    # ì¡°ê±´ë¶€ í‘œì‹œ
    show_conditions: Dict[str, Any] = field(default_factory=dict)


@dataclass
class DriverGazeState:
    """ìš´ì „ì ì‹œì„  ìƒíƒœ"""

    current_region: GazeRegion
    gaze_point: Tuple[float, float]  # ì •ê·œí™”ëœ ì¢Œí‘œ (0-1)
    attention_score: float
    fixation_duration: float  # í˜„ì¬ ì˜ì—­ ê³ ì • ì‹œê°„
    saccade_velocity: float  # ì‚¬ì¹´ë“œ ì†ë„
    predicted_next_region: Optional[GazeRegion] = None
    confidence: float = 1.0


@dataclass
class VehicleContext:
    """ì°¨ëŸ‰ ìƒí™© ì •ë³´"""

    speed_kmh: float = 0.0
    steering_angle: float = 0.0
    turn_signal: Optional[str] = None  # "left", "right", None
    gear: str = "P"  # P, R, N, D, S

    # ì£¼ë³€ í™˜ê²½
    detected_objects: List[Dict[str, Any]] = field(default_factory=list)
    lane_info: Dict[str, Any] = field(default_factory=dict)
    traffic_signs: List[Dict[str, Any]] = field(default_factory=list)

    # ë„¤ë¹„ê²Œì´ì…˜
    next_maneuver: Optional[Dict[str, Any]] = None
    distance_to_maneuver: float = 0.0


class ARHUDSystem:
    """ìƒí™©ì¸ì§€í˜• AR HUD ë©”ì¸ ì‹œìŠ¤í…œ"""

    def __init__(self, screen_width: int = 1920, screen_height: int = 1080):
        self.config = get_config()
        self.screen_width = screen_width
        self.screen_height = screen_height

        # AR ê°ì²´ ê´€ë¦¬
        self.ar_objects: Dict[str, ARObject] = {}
        self.object_update_queue = deque(maxlen=1000)

        # ì‹œì„  ì¶”ì 
        self.gaze_tracker = GazeRegionTracker()
        self.current_gaze_state = DriverGazeState(
            current_region=GazeRegion.CENTER,
            gaze_point=(0.5, 0.5),
            attention_score=1.0,
            fixation_duration=0.0,
            saccade_velocity=0.0,
        )

        # ìƒí™© ì¸ì‹ ì—”ì§„
        self.context_analyzer = ContextAnalyzer()
        self.intention_predictor = IntentionPredictor()

        # ë Œë”ë§ ì—”ì§„
        self.ar_renderer = ARRenderer(screen_width, screen_height)

        # ì„¤ì •
        self.enable_predictive_highlighting = True
        self.adaptive_brightness = True
        self.min_fixation_time = 0.2  # ìµœì†Œ ì‹œì„  ê³ ì • ì‹œê°„

        print(f"ğŸ¥½ AR HUD ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   í™”ë©´ í•´ìƒë„: {screen_width}x{screen_height}")
        print(
            f"   ì˜ˆì¸¡ í•˜ì´ë¼ì´íŒ…: {'ON' if self.enable_predictive_highlighting else 'OFF'}"
        )

    async def process_frame(
        self, ui_state: UIState, vehicle_context: VehicleContext
    ) -> np.ndarray:
        """í”„ë ˆì„ ì²˜ë¦¬ ë° AR ì˜¤ë²„ë ˆì´ ìƒì„±"""

        # 1. ì‹œì„  ìƒíƒœ ì—…ë°ì´íŠ¸
        await self._update_gaze_state(ui_state.gaze)

        # 2. ìƒí™© ë¶„ì„
        context_info = await self.context_analyzer.analyze_situation(
            vehicle_context, self.current_gaze_state
        )

        # 3. ìš´ì „ì ì˜ë„ ì˜ˆì¸¡
        driver_intention = await self.intention_predictor.predict_intention(
            self.current_gaze_state, vehicle_context, context_info
        )

        # 4. AR ê°ì²´ ìƒì„±/ì—…ë°ì´íŠ¸
        await self._update_ar_objects(
            ui_state, vehicle_context, context_info, driver_intention
        )

        # 5. ì‹œì„  ê¸°ë°˜ ì ì‘í˜• í‘œì‹œ
        await self._adapt_display_to_gaze()

        # 6. AR í”„ë ˆì„ ë Œë”ë§
        ar_frame = await self.ar_renderer.render_frame(
            self.ar_objects,
            self.current_gaze_state,
            adaptive_brightness=self.adaptive_brightness,
        )

        return ar_frame

    async def _update_gaze_state(self, gaze_data: GazeData):
        """ì‹œì„  ìƒíƒœ ì—…ë°ì´íŠ¸"""
        # ì‹œì„  ì˜ì—­ íŒì •
        current_region = self.gaze_tracker.determine_gaze_region(
            gaze_data.gaze_x, gaze_data.gaze_y
        )

        # ê³ ì • ì‹œê°„ ê³„ì‚°
        if current_region == self.current_gaze_state.current_region:
            self.current_gaze_state.fixation_duration += 1 / 30.0  # 30fps ê°€ì •
        else:
            self.current_gaze_state.fixation_duration = 0.0
            self.current_gaze_state.current_region = current_region

        # ì‹œì„  ì¢Œí‘œ ì—…ë°ì´íŠ¸
        self.current_gaze_state.gaze_point = (gaze_data.gaze_x, gaze_data.gaze_y)
        self.current_gaze_state.attention_score = gaze_data.attention_score

        # ì‚¬ì¹´ë“œ ì†ë„ ê³„ì‚° (ì‹œì„  ì´ë™ ì†ë„)
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì´ì „ í”„ë ˆì„ê³¼ì˜ ì°¨ì´ë¡œ ê³„ì‚°
        self.current_gaze_state.saccade_velocity = gaze_data.saccade_velocity

    async def _update_ar_objects(
        self,
        ui_state: UIState,
        vehicle_context: VehicleContext,
        context_info: Dict[str, Any],
        driver_intention: Dict[str, Any],
    ):
        """AR ê°ì²´ ìƒì„± ë° ì—…ë°ì´íŠ¸"""

        # ê¸°ì¡´ ê°ì²´ ì •ë¦¬ (ë§Œë£Œëœ ê°ì²´ ì œê±°)
        await self._cleanup_expired_objects()

        # 1. ì•ˆì „ ê²½ê³  ê°ì²´ ìƒì„±
        await self._create_safety_warnings(ui_state, context_info)

        # 2. ë„¤ë¹„ê²Œì´ì…˜ ê°€ì´ë“œ ìƒì„±
        await self._create_navigation_guides(vehicle_context)

        # 3. ì°¨ì„  ë³€ê²½ ì§€ì›
        await self._create_lane_change_assistance(driver_intention, vehicle_context)

        # 4. ìœ„í—˜ ìš”ì†Œ í•˜ì´ë¼ì´íŒ…
        await self._create_hazard_highlighting(context_info)

        # 5. ìƒì²´ ì •ë³´ ì˜¤ë²„ë ˆì´
        await self._create_biometric_overlay(ui_state)

    async def _create_safety_warnings(
        self, ui_state: UIState, context_info: Dict[str, Any]
    ):
        """ì•ˆì „ ê²½ê³  AR ê°ì²´ ìƒì„±"""

        # ì£¼ì˜ì‚°ë§Œ ê²½ê³ 
        if ui_state.gaze.distraction_level > 0.7:
            await self._create_attention_warning()

        # ì¡¸ìŒ ê²½ê³ 
        if ui_state.face.drowsiness_level > 0.6:
            await self._create_drowsiness_warning()

        # ìœ„í—˜ ë¬¼ì²´ ê²½ê³ 
        high_risk_objects = context_info.get("high_risk_objects", [])
        for obj in high_risk_objects:
            await self._create_object_warning_box(obj)

    async def _create_attention_warning(self):
        """ì£¼ì˜ì‚°ë§Œ ê²½ê³  ìƒì„±"""
        warning_box = ARObject(
            object_id="attention_warning",
            object_type=ARObjectType.WARNING_BOX,
            priority=ARPriority.HIGH,
            world_position=(0.0, 0.0, 5.0),  # ì „ë°© 5m
            screen_position=(self.screen_width // 2, self.screen_height // 3),
            size=(400, 100),
            color=(255, 140, 0, 200),  # ì£¼í™©ìƒ‰
            text="ì£¼ì˜ë ¥ ì§‘ì¤‘ í•„ìš”!",
            blink_rate=2.0,  # 2Hz ê¹œë¹¡ì„
            fade_duration=3.0,
        )
        self.ar_objects["attention_warning"] = warning_box

    async def _create_drowsiness_warning(self):
        """ì¡¸ìŒ ê²½ê³  ìƒì„±"""
        warning_box = ARObject(
            object_id="drowsiness_warning",
            object_type=ARObjectType.WARNING_BOX,
            priority=ARPriority.CRITICAL,
            world_position=(0.0, 0.0, 3.0),
            screen_position=(self.screen_width // 2, self.screen_height // 4),
            size=(500, 120),
            color=(255, 0, 0, 220),  # ë¹¨ê°„ìƒ‰
            text="ì¡¸ìŒ ê°ì§€! íœ´ì‹ í•„ìš”",
            blink_rate=3.0,
            fade_duration=5.0,
        )
        self.ar_objects["drowsiness_warning"] = warning_box

    async def _create_object_warning_box(self, risk_object: Dict[str, Any]):
        """ìœ„í—˜ ê°ì²´ ê²½ê³  ë°•ìŠ¤ ìƒì„±"""
        obj_id = f"risk_object_{risk_object.get('id', int(time.time()))}"

        # ê°ì²´ ìœ„ì¹˜ë¥¼ í™”ë©´ ì¢Œí‘œë¡œ ë³€í™˜
        screen_x, screen_y = self._world_to_screen(
            risk_object.get("position", (0, 0, 10))
        )

        warning_box = ARObject(
            object_id=obj_id,
            object_type=ARObjectType.WARNING_BOX,
            priority=ARPriority.HIGH,
            world_position=risk_object.get("position", (0, 0, 10)),
            screen_position=(screen_x, screen_y),
            size=(150, 100),
            color=(255, 0, 0, 180),
            text=f"ìœ„í—˜: {risk_object.get('type', 'ë¬¼ì²´')}",
            blink_rate=2.5,
            fade_duration=2.0,
        )
        self.ar_objects[obj_id] = warning_box

    async def _create_navigation_guides(self, vehicle_context: VehicleContext):
        """ë„¤ë¹„ê²Œì´ì…˜ ê°€ì´ë“œ AR ê°ì²´ ìƒì„±"""
        if not vehicle_context.next_maneuver:
            return

        maneuver = vehicle_context.next_maneuver
        distance = vehicle_context.distance_to_maneuver

        # ë„¤ë¹„ê²Œì´ì…˜ í™”ì‚´í‘œ ìƒì„±
        if maneuver.get("type") == "turn_right":
            await self._create_turn_arrow("right", distance)
        elif maneuver.get("type") == "turn_left":
            await self._create_turn_arrow("left", distance)
        elif maneuver.get("type") == "straight":
            await self._create_straight_arrow(distance)

    async def _create_turn_arrow(self, direction: str, distance: float):
        """íšŒì „ í™”ì‚´í‘œ ìƒì„±"""
        # ì‹¤ì œ ë„ë¡œì˜ íšŒì „ ì§€ì ì— AR í™”ì‚´í‘œ í‘œì‹œ
        if distance <= 100:  # 100m ì´ë‚´ì—ì„œë§Œ í‘œì‹œ
            arrow_id = f"nav_arrow_{direction}"

            # íšŒì „ ì§€ì  ì¢Œí‘œ ê³„ì‚° (ì‹¤ì œë¡œëŠ” GPS + ë§µ ë°ì´í„° í™œìš©)
            target_position = self._calculate_maneuver_position(direction, distance)
            screen_x, screen_y = self._world_to_screen(target_position)

            arrow = ARObject(
                object_id=arrow_id,
                object_type=ARObjectType.NAVIGATION_ARROW,
                priority=ARPriority.MEDIUM,
                world_position=target_position,
                screen_position=(screen_x, screen_y),
                size=(80, 80),
                color=(0, 255, 255, 200),  # ì‹œì•ˆìƒ‰
                icon=f"arrow_{direction}",
                text=f"{distance:.0f}m",
            )
            self.ar_objects[arrow_id] = arrow

    async def _create_lane_change_assistance(
        self, driver_intention: Dict[str, Any], vehicle_context: VehicleContext
    ):
        """ì°¨ì„  ë³€ê²½ ì§€ì› AR ìƒì„±"""
        intended_direction = driver_intention.get("lane_change_direction")

        if intended_direction:
            # ëª©í‘œ ì°¨ì„  í•˜ì´ë¼ì´íŒ…
            await self._highlight_target_lane(intended_direction)

            # ì‚¬ê°ì§€ëŒ€ ê²½ê³ 
            if self._check_blind_spot_risk(intended_direction, vehicle_context):
                await self._create_blind_spot_warning(intended_direction)

    async def _highlight_target_lane(self, direction: str):
        """ëª©í‘œ ì°¨ì„  í•˜ì´ë¼ì´íŒ…"""
        lane_id = f"target_lane_{direction}"

        # ì°¨ì„  ì˜ì—­ ê³„ì‚° (ì‹¤ì œë¡œëŠ” ì°¨ì„  ì¸ì‹ ë°ì´í„° í™œìš©)
        lane_points = self._calculate_lane_boundary(direction)

        lane_highlight = ARObject(
            object_id=lane_id,
            object_type=ARObjectType.LANE_HIGHLIGHT,
            priority=ARPriority.MEDIUM,
            world_position=(0.0, 0.0, 20.0),  # ì „ë°© 20m
            screen_position=(self.screen_width // 2, self.screen_height // 2),
            size=(200, 600),
            color=(0, 255, 0, 100),  # ë°˜íˆ¬ëª… ë…¹ìƒ‰
            blink_rate=1.0,
            fade_duration=5.0,
        )
        self.ar_objects[lane_id] = lane_highlight

    async def _create_blind_spot_warning(self, direction: str):
        """ì‚¬ê°ì§€ëŒ€ ê²½ê³  ìƒì„±"""
        warning_id = f"blind_spot_{direction}"

        # ì‚¬ê°ì§€ëŒ€ ìœ„ì¹˜ì— ê²½ê³  í‘œì‹œ
        if direction == "left":
            screen_pos = (100, self.screen_height // 2)
        else:
            screen_pos = (self.screen_width - 100, self.screen_height // 2)

        blind_spot_warning = ARObject(
            object_id=warning_id,
            object_type=ARObjectType.BLIND_SPOT_ALERT,
            priority=ARPriority.HIGH,
            world_position=(-3.0 if direction == "left" else 3.0, 0.0, 0.0),
            screen_position=screen_pos,
            size=(120, 120),
            color=(255, 0, 0, 200),
            text="ì‚¬ê°ì§€ëŒ€ ìœ„í—˜!",
            blink_rate=3.0,
            fade_duration=3.0,
        )
        self.ar_objects[warning_id] = blind_spot_warning

    async def _create_hazard_highlighting(self, context_info: Dict[str, Any]):
        """ìœ„í—˜ ìš”ì†Œ í•˜ì´ë¼ì´íŒ…"""
        hazards = context_info.get("potential_hazards", [])

        for hazard in hazards:
            hazard_id = f"hazard_{hazard.get('id', int(time.time()))}"

            screen_x, screen_y = self._world_to_screen(
                hazard.get("position", (0, 0, 15))
            )

            hazard_marker = ARObject(
                object_id=hazard_id,
                object_type=ARObjectType.HAZARD_MARKER,
                priority=ARPriority.MEDIUM,
                world_position=hazard.get("position", (0, 0, 15)),
                screen_position=(screen_x, screen_y),
                size=(60, 60),
                color=(255, 255, 0, 160),  # ë…¸ë€ìƒ‰
                icon="warning",
                text=hazard.get("type", "ì£¼ì˜"),
                fade_duration=4.0,
            )
            self.ar_objects[hazard_id] = hazard_marker

    async def _create_biometric_overlay(self, ui_state: UIState):
        """ìƒì²´ ì •ë³´ ì˜¤ë²„ë ˆì´ ìƒì„±"""
        # ì‹¬ë°•ìˆ˜ í‘œì‹œ (ì˜µì…˜)
        if ui_state.biometrics.heart_rate and ui_state.biometrics.heart_rate > 0:
            hr_overlay = ARObject(
                object_id="heart_rate_overlay",
                object_type=ARObjectType.BIOMETRIC_OVERLAY,
                priority=ARPriority.INFO,
                world_position=(0.0, 0.0, 0.0),
                screen_position=(self.screen_width - 150, 50),
                size=(120, 30),
                color=(255, 255, 255, 150),
                text=f"â™¥ {ui_state.biometrics.heart_rate:.0f} BPM",
            )
            self.ar_objects["heart_rate_overlay"] = hr_overlay

    async def _adapt_display_to_gaze(self):
        """ì‹œì„  ê¸°ë°˜ ì ì‘í˜• í‘œì‹œ"""
        if not self.enable_predictive_highlighting:
            return

        gaze_region = self.current_gaze_state.current_region
        fixation_time = self.current_gaze_state.fixation_duration

        # ì‹œì„  ì˜ì—­ë³„ ê°ì²´ ë°ê¸° ì¡°ì •
        for obj_id, ar_obj in self.ar_objects.items():
            # ì‹œì„ ì´ ì˜¤ë˜ ê³ ì •ëœ ì˜ì—­ì˜ ê°ì²´ëŠ” ë°ê¸° ê°ì†Œ
            if self._is_object_in_gaze_region(ar_obj, gaze_region):
                if fixation_time > 2.0:  # 2ì´ˆ ì´ìƒ ê³ ì •
                    # ë°ê¸° ê°ì†Œ (ì£¼ì˜ì‚°ë§Œ ë°©ì§€)
                    r, g, b, a = ar_obj.color
                    ar_obj.color = (r, g, b, max(50, a - 30))
            else:
                # ì‹œì„ ì´ ì—†ëŠ” ì˜ì—­ì˜ ì¤‘ìš” ê°ì²´ëŠ” ë°ê¸° ì¦ê°€
                if ar_obj.priority in [ARPriority.CRITICAL, ARPriority.HIGH]:
                    r, g, b, a = ar_obj.color
                    ar_obj.color = (r, g, b, min(255, a + 20))

    def _is_object_in_gaze_region(
        self, ar_obj: ARObject, gaze_region: GazeRegion
    ) -> bool:
        """AR ê°ì²´ê°€ ì‹œì„  ì˜ì—­ì— ìˆëŠ”ì§€ í™•ì¸"""
        obj_x, obj_y = ar_obj.screen_position

        # ê°„ë‹¨í•œ ì˜ì—­ íŒì • (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ê³„ì‚° í•„ìš”)
        if gaze_region == GazeRegion.CENTER:
            return (
                self.screen_width // 4 <= obj_x <= 3 * self.screen_width // 4
                and self.screen_height // 4 <= obj_y <= 3 * self.screen_height // 4
            )
        elif gaze_region == GazeRegion.LEFT_MIRROR:
            return obj_x <= self.screen_width // 4
        elif gaze_region == GazeRegion.RIGHT_MIRROR:
            return obj_x >= 3 * self.screen_width // 4

        return False

    async def _cleanup_expired_objects(self):
        """ë§Œë£Œëœ AR ê°ì²´ ì •ë¦¬"""
        current_time = time.time()
        expired_objects = []

        for obj_id, ar_obj in self.ar_objects.items():
            # í˜ì´ë“œ ì§€ì†ì‹œê°„ì´ ìˆëŠ” ê°ì²´ ì²´í¬
            if (
                ar_obj.fade_duration > 0
                and current_time - ar_obj.created_at > ar_obj.fade_duration
            ):
                expired_objects.append(obj_id)

        for obj_id in expired_objects:
            del self.ar_objects[obj_id]

    def _world_to_screen(
        self, world_pos: Tuple[float, float, float]
    ) -> Tuple[int, int]:
        """ì›”ë“œ ì¢Œí‘œë¥¼ í™”ë©´ ì¢Œí‘œë¡œ ë³€í™˜"""
        x, y, z = world_pos

        # ê°„ë‹¨í•œ íˆ¬ì˜ ë³€í™˜ (ì‹¤ì œë¡œëŠ” ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í•„ìš”)
        if z > 0:
            # ì›ê·¼ íˆ¬ì˜
            focal_length = 800  # ê°€ìƒ ì´ˆì ê±°ë¦¬
            screen_x = int(self.screen_width // 2 + (x * focal_length / z))
            screen_y = int(self.screen_height // 2 - (y * focal_length / z))
        else:
            screen_x = self.screen_width // 2
            screen_y = self.screen_height // 2

        # í™”ë©´ ë²”ìœ„ í´ë¨í•‘
        screen_x = max(0, min(self.screen_width, screen_x))
        screen_y = max(0, min(self.screen_height, screen_y))

        return screen_x, screen_y

    def _calculate_maneuver_position(
        self, direction: str, distance: float
    ) -> Tuple[float, float, float]:
        """ì¡°ì‘ ìœ„ì¹˜ ê³„ì‚°"""
        # ê°„ë‹¨í•œ ê³„ì‚° (ì‹¤ì œë¡œëŠ” GPS + HDë§µ ë°ì´í„° í™œìš©)
        if direction == "left":
            return (-2.0, 0.0, distance)
        elif direction == "right":
            return (2.0, 0.0, distance)
        else:
            return (0.0, 0.0, distance)

    def _calculate_lane_boundary(self, direction: str) -> List[Tuple[float, float]]:
        """ì°¨ì„  ê²½ê³„ ê³„ì‚°"""
        # ì°¨ì„  ì¸ì‹ ë°ì´í„°ë¥¼ í™œìš©í•œ ì‹¤ì œ ì°¨ì„  ì¢Œí‘œ ê³„ì‚°
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œ
        if direction == "left":
            return [(-2.0, 0.0), (-2.0, 50.0), (-5.0, 50.0), (-5.0, 0.0)]
        else:
            return [(2.0, 0.0), (2.0, 50.0), (5.0, 50.0), (5.0, 0.0)]

    def _check_blind_spot_risk(
        self, direction: str, vehicle_context: VehicleContext
    ) -> bool:
        """ì‚¬ê°ì§€ëŒ€ ìœ„í—˜ ì²´í¬"""
        # ì‹¤ì œë¡œëŠ” ë ˆì´ë”/ì¹´ë©”ë¼ ì„¼ì„œ ë°ì´í„° í™œìš©
        detected_objects = vehicle_context.detected_objects

        for obj in detected_objects:
            obj_pos = obj.get("position", (0, 0, 0))
            obj_x = obj_pos[0]

            if direction == "left" and -5.0 <= obj_x <= -1.0:
                return True
            elif direction == "right" and 1.0 <= obj_x <= 5.0:
                return True

        return False

    def get_ar_statistics(self) -> Dict[str, Any]:
        """AR ì‹œìŠ¤í…œ í†µê³„"""
        stats = {
            "active_objects": len(self.ar_objects),
            "objects_by_type": {},
            "objects_by_priority": {},
            "current_gaze_region": self.current_gaze_state.current_region.value,
            "gaze_fixation_time": self.current_gaze_state.fixation_duration,
            "adaptive_features_enabled": self.enable_predictive_highlighting,
        }

        # íƒ€ì…ë³„ í†µê³„
        for ar_obj in self.ar_objects.values():
            obj_type = ar_obj.object_type.value
            priority = ar_obj.priority.value

            stats["objects_by_type"][obj_type] = (
                stats["objects_by_type"].get(obj_type, 0) + 1
            )
            stats["objects_by_priority"][priority] = (
                stats["objects_by_priority"].get(priority, 0) + 1
            )

        return stats


class GazeRegionTracker:
    """ì‹œì„  ì˜ì—­ ì¶”ì ê¸°"""

    def __init__(self):
        self.region_boundaries = self._initialize_region_boundaries()

    def _initialize_region_boundaries(self) -> Dict[GazeRegion, Dict[str, float]]:
        """ì‹œì„  ì˜ì—­ ê²½ê³„ ì„¤ì •"""
        return {
            GazeRegion.CENTER: {
                "x_min": 0.25,
                "x_max": 0.75,
                "y_min": 0.25,
                "y_max": 0.75,
            },
            GazeRegion.LEFT_MIRROR: {
                "x_min": 0.0,
                "x_max": 0.2,
                "y_min": 0.3,
                "y_max": 0.6,
            },
            GazeRegion.RIGHT_MIRROR: {
                "x_min": 0.8,
                "x_max": 1.0,
                "y_min": 0.3,
                "y_max": 0.6,
            },
            GazeRegion.REAR_MIRROR: {
                "x_min": 0.4,
                "x_max": 0.6,
                "y_min": 0.0,
                "y_max": 0.2,
            },
            GazeRegion.DASHBOARD: {
                "x_min": 0.3,
                "x_max": 0.7,
                "y_min": 0.8,
                "y_max": 1.0,
            },
        }

    def determine_gaze_region(self, gaze_x: float, gaze_y: float) -> GazeRegion:
        """ì‹œì„  ì¢Œí‘œë¡œë¶€í„° ì˜ì—­ íŒì •"""
        for region, bounds in self.region_boundaries.items():
            if (
                bounds["x_min"] <= gaze_x <= bounds["x_max"]
                and bounds["y_min"] <= gaze_y <= bounds["y_max"]
            ):
                return region

        return GazeRegion.CENTER  # ê¸°ë³¸ê°’


class ContextAnalyzer:
    """ìƒí™© ë¶„ì„ ì—”ì§„"""

    async def analyze_situation(
        self, vehicle_context: VehicleContext, gaze_state: DriverGazeState
    ) -> Dict[str, Any]:
        """ìƒí™© ë¶„ì„"""
        analysis = {
            "risk_level": "low",
            "high_risk_objects": [],
            "potential_hazards": [],
            "driver_attention_state": "normal",
            "environmental_factors": {},
        }

        # ì†ë„ ê¸°ë°˜ ìœ„í—˜ë„ ë¶„ì„
        if vehicle_context.speed_kmh > 80:
            analysis["risk_level"] = "high"
        elif vehicle_context.speed_kmh > 50:
            analysis["risk_level"] = "medium"

        # ì£¼ì˜ë ¥ ìƒíƒœ ë¶„ì„
        if gaze_state.attention_score < 0.5:
            analysis["driver_attention_state"] = "distracted"
        elif gaze_state.fixation_duration > 3.0:
            analysis["driver_attention_state"] = "tunnel_vision"

        # ê°ì§€ëœ ê°ì²´ ìœ„í—˜ë„ í‰ê°€
        for obj in vehicle_context.detected_objects:
            risk_score = self._calculate_object_risk(obj, vehicle_context)
            if risk_score > 0.7:
                analysis["high_risk_objects"].append({**obj, "risk_score": risk_score})

        return analysis

    def _calculate_object_risk(
        self, obj: Dict[str, Any], context: VehicleContext
    ) -> float:
        """ê°ì²´ ìœ„í—˜ë„ ê³„ì‚°"""
        base_risk = 0.0

        # ê°ì²´ íƒ€ì…ë³„ ê¸°ë³¸ ìœ„í—˜ë„
        obj_type = obj.get("type", "unknown")
        if obj_type == "pedestrian":
            base_risk = 0.8
        elif obj_type == "vehicle":
            base_risk = 0.6
        elif obj_type == "cyclist":
            base_risk = 0.7

        # ê±°ë¦¬ ê¸°ë°˜ ìœ„í—˜ë„ ì¡°ì •
        distance = obj.get("distance", 100)
        if distance < 10:
            base_risk *= 1.5
        elif distance < 20:
            base_risk *= 1.2

        # ì†ë„ ê¸°ë°˜ ì¡°ì •
        if context.speed_kmh > 60:
            base_risk *= 1.3

        return min(1.0, base_risk)


class IntentionPredictor:
    """ìš´ì „ì ì˜ë„ ì˜ˆì¸¡ê¸°"""

    async def predict_intention(
        self,
        gaze_state: DriverGazeState,
        vehicle_context: VehicleContext,
        context_info: Dict[str, Any],
    ) -> Dict[str, Any]:
        """ìš´ì „ì ì˜ë„ ì˜ˆì¸¡"""
        intention = {
            "lane_change_direction": None,
            "lane_change_probability": 0.0,
            "turn_intention": None,
            "stopping_probability": 0.0,
            "confidence": 0.0,
        }

        # ì°¨ì„  ë³€ê²½ ì˜ë„ ì˜ˆì¸¡
        if vehicle_context.turn_signal:
            intention["lane_change_direction"] = vehicle_context.turn_signal
            intention["lane_change_probability"] = 0.9
            intention["confidence"] = 0.9

        # ì‹œì„  íŒ¨í„´ ê¸°ë°˜ ì˜ˆì¸¡
        if gaze_state.current_region == GazeRegion.LEFT_MIRROR:
            if gaze_state.fixation_duration > 1.0:
                intention["lane_change_direction"] = "left"
                intention["lane_change_probability"] = 0.7
                intention["confidence"] = 0.7

        elif gaze_state.current_region == GazeRegion.RIGHT_MIRROR:
            if gaze_state.fixation_duration > 1.0:
                intention["lane_change_direction"] = "right"
                intention["lane_change_probability"] = 0.7
                intention["confidence"] = 0.7

        # í•¸ë“¤ ì¡°ì‘ íŒ¨í„´ ê³ ë ¤
        if abs(vehicle_context.steering_angle) > 5:
            if vehicle_context.steering_angle > 0:
                intention["turn_intention"] = "right"
            else:
                intention["turn_intention"] = "left"

        return intention


class ARRenderer:
    """AR ë Œë”ë§ ì—”ì§„ - ë©”ëª¨ë¦¬ ìµœì í™”"""

    def __init__(self, screen_width: int, screen_height: int):
        self.screen_width = screen_width
        self.screen_height = screen_height

        # í”„ë ˆì„ ë²„í¼ ì¬ì‚¬ìš©ì„ ìœ„í•œ ì˜êµ¬ í• ë‹¹
        self.frame_buffer = np.zeros((screen_height, screen_width, 4), dtype=np.uint8)
        self._buffer_initialized = True

        # ì„±ëŠ¥ ì¶”ì 
        self._render_count = 0
        self._last_cleanup_time = time.time()
        self._cleanup_interval = 300.0  # 5ë¶„ë§ˆë‹¤ ì •ë¦¬

    async def render_frame(
        self,
        ar_objects: Dict[str, ARObject],
        gaze_state: DriverGazeState,
        adaptive_brightness: bool = True,
    ) -> np.ndarray:
        """AR í”„ë ˆì„ ë Œë”ë§ - ë©”ëª¨ë¦¬ ìµœì í™”"""
        self._render_count += 1

        # í”„ë ˆì„ ë²„í¼ ì´ˆê¸°í™” (ì¬í• ë‹¹ ì—†ì´ ì œë¡œí™”)
        self.frame_buffer.fill(0)

        # ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ê°ì²´ ë Œë”ë§
        sorted_objects = sorted(ar_objects.values(), key=lambda obj: obj.priority.value)

        for ar_obj in sorted_objects:
            if ar_obj.is_visible:
                await self._render_object(ar_obj, adaptive_brightness)

        # ì‹œì„  ìœ„ì¹˜ í‘œì‹œ (ë””ë²„ê·¸ìš©, ì‹¤ì œë¡œëŠ” ë¹„í™œì„±í™”)
        if False:  # ë””ë²„ê·¸ ëª¨ë“œì—ì„œë§Œ
            await self._render_gaze_indicator(gaze_state)

        # ì£¼ê¸°ì  ë©”ëª¨ë¦¬ ì •ë¦¬
        current_time = time.time()
        if current_time - self._last_cleanup_time > self._cleanup_interval:
            self._perform_memory_cleanup()
            self._last_cleanup_time = current_time

        return self.frame_buffer

    def _perform_memory_cleanup(self):
        """ì£¼ê¸°ì  ë©”ëª¨ë¦¬ ì •ë¦¬"""
        try:
            # í”„ë ˆì„ ë²„í¼ í¬ê¸° í™•ì¸ ë° í•„ìš”ì‹œ ì¬í• ë‹¹
            expected_size = (self.screen_height, self.screen_width, 4)
            if self.frame_buffer.shape != expected_size:
                logger.warning(
                    f"í”„ë ˆì„ ë²„í¼ í¬ê¸° ë¶ˆì¼ì¹˜ ê°ì§€: {self.frame_buffer.shape} != {expected_size}"
                )
                self.frame_buffer = np.zeros(expected_size, dtype=np.uint8)
                logger.info("í”„ë ˆì„ ë²„í¼ ì¬í• ë‹¹ ì™„ë£Œ")

            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰ (ì£¼ì˜: ì„±ëŠ¥ì— ì˜í–¥)
            import gc

            collected = gc.collect()

            logger.debug(
                f"AR ë Œë”ëŸ¬ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ - ë Œë”ë§ íšŸìˆ˜: {self._render_count}, "
                f"ìˆ˜ì§‘ëœ ê°ì²´: {collected}ê°œ"
            )

        except Exception as e:
            logger.error(f"AR ë Œë”ëŸ¬ ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    def resize_buffer(self, new_width: int, new_height: int):
        """í”„ë ˆì„ ë²„í¼ í¬ê¸° ë³€ê²½ - ë©”ëª¨ë¦¬ íš¨ìœ¨ì """
        if new_width != self.screen_width or new_height != self.screen_height:
            logger.info(
                f"AR ë Œë”ëŸ¬ ë²„í¼ í¬ê¸° ë³€ê²½: {self.screen_width}x{self.screen_height} -> {new_width}x{new_height}"
            )

            self.screen_width = new_width
            self.screen_height = new_height

            # ìƒˆë¡œìš´ í¬ê¸°ë¡œ ë²„í¼ ì¬í• ë‹¹
            self.frame_buffer = np.zeros((new_height, new_width, 4), dtype=np.uint8)

            logger.info("AR ë Œë”ëŸ¬ ë²„í¼ í¬ê¸° ë³€ê²½ ì™„ë£Œ")

    async def _render_object(self, ar_obj: ARObject, adaptive_brightness: bool):
        """ê°œë³„ AR ê°ì²´ ë Œë”ë§"""
        x, y = ar_obj.screen_position
        w, h = ar_obj.size

        # í™”ë©´ ê²½ê³„ ê²€ì‚¬
        if x < 0 or y < 0 or x >= self.screen_width or y >= self.screen_height:
            return  # í™”ë©´ ë°– ê°ì²´ëŠ” ë Œë”ë§ ìƒëµ

        # ê¹œë¹¡ì„ ì²˜ë¦¬
        if ar_obj.blink_rate > 0:
            blink_phase = (time.time() * ar_obj.blink_rate) % 1.0
            if blink_phase > 0.5:
                return  # ê¹œë¹¡ì„ ìƒíƒœì—ì„œëŠ” ë Œë”ë§ ì•ˆí•¨

        # ìƒ‰ìƒ ì„¤ì •
        color = ar_obj.color
        if adaptive_brightness:
            # í™˜ê²½ ë°ê¸°ì— ë”°ë¥¸ ì ì‘í˜• ìƒ‰ìƒ ì¡°ì •
            # ì‹¤ì œë¡œëŠ” ì£¼ë³€ ì¡°ë„ ì„¼ì„œ ë°ì´í„° í™œìš©
            color = self._adjust_color_for_brightness(color)

        # ê°ì²´ íƒ€ì…ë³„ ë Œë”ë§
        if ar_obj.object_type == ARObjectType.WARNING_BOX:
            await self._draw_warning_box(x, y, w, h, color, ar_obj.text)

        elif ar_obj.object_type == ARObjectType.NAVIGATION_ARROW:
            await self._draw_navigation_arrow(x, y, w, h, color, ar_obj.icon)

        elif ar_obj.object_type == ARObjectType.LANE_HIGHLIGHT:
            await self._draw_lane_highlight(x, y, w, h, color)

        elif ar_obj.object_type == ARObjectType.HAZARD_MARKER:
            await self._draw_hazard_marker(x, y, w, h, color, ar_obj.text)

        elif ar_obj.object_type == ARObjectType.BIOMETRIC_OVERLAY:
            await self._draw_text_overlay(x, y, color, ar_obj.text)

    async def _draw_warning_box(
        self,
        x: int,
        y: int,
        w: int,
        h: int,
        color: Tuple[int, int, int, int],
        text: str,
    ):
        """ê²½ê³  ë°•ìŠ¤ ê·¸ë¦¬ê¸°"""
        # ë°•ìŠ¤ í…Œë‘ë¦¬
        cv2.rectangle(
            self.frame_buffer,
            (x - w // 2, y - h // 2),
            (x + w // 2, y + h // 2),
            color,
            3,
        )

        # í…ìŠ¤íŠ¸
        if text:
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.8
            thickness = 2
            text_size = cv2.getTextSize(text, font, font_scale, thickness)[0]
            text_x = x - text_size[0] // 2
            text_y = y + text_size[1] // 2

            cv2.putText(
                self.frame_buffer,
                text,
                (text_x, text_y),
                font,
                font_scale,
                color[:3],
                thickness,
            )

    async def _draw_navigation_arrow(
        self,
        x: int,
        y: int,
        w: int,
        h: int,
        color: Tuple[int, int, int, int],
        icon: str,
    ):
        """ë„¤ë¹„ê²Œì´ì…˜ í™”ì‚´í‘œ ê·¸ë¦¬ê¸°"""
        # í™”ì‚´í‘œ í¬ì¸íŠ¸ ê³„ì‚°
        if "right" in icon:
            points = np.array(
                [[x - w // 4, y - h // 4], [x + w // 4, y], [x - w // 4, y + h // 4]],
                np.int32,
            )
        elif "left" in icon:
            points = np.array(
                [[x + w // 4, y - h // 4], [x - w // 4, y], [x + w // 4, y + h // 4]],
                np.int32,
            )
        else:  # ì§ì§„
            points = np.array(
                [[x - w // 4, y + h // 4], [x, y - h // 4], [x + w // 4, y + h // 4]],
                np.int32,
            )

        cv2.fillPoly(self.frame_buffer, [points], color[:3])

    async def _draw_lane_highlight(
        self, x: int, y: int, w: int, h: int, color: Tuple[int, int, int, int]
    ):
        """ì°¨ì„  í•˜ì´ë¼ì´íŠ¸ ê·¸ë¦¬ê¸° - ë©”ëª¨ë¦¬ ìµœì í™”"""
        # ì„ì‹œ ì˜¤ë²„ë ˆì´ë¥¼ ìœ„í•œ ì‘ì€ ì˜ì—­ë§Œ ë³µì‚¬
        x1, y1 = max(0, x - w // 2), max(0, y - h // 2)
        x2, y2 = min(self.screen_width, x + w // 2), min(self.screen_height, y + h // 2)

        if x2 <= x1 or y2 <= y1:
            return  # ìœ íš¨í•˜ì§€ ì•Šì€ ì˜ì—­

        # ì‘ì€ ì˜ì—­ë§Œ ì²˜ë¦¬í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ
        region = self.frame_buffer[y1:y2, x1:x2].copy()
        cv2.rectangle(region, (0, 0), (x2 - x1, y2 - y1), color[:3], -1)

        alpha = color[3] / 255.0
        cv2.addWeighted(
            region,
            alpha,
            self.frame_buffer[y1:y2, x1:x2],
            1 - alpha,
            0,
            self.frame_buffer[y1:y2, x1:x2],
        )

    async def _draw_hazard_marker(
        self,
        x: int,
        y: int,
        w: int,
        h: int,
        color: Tuple[int, int, int, int],
        text: str,
    ):
        """ìœ„í—˜ ë§ˆì»¤ ê·¸ë¦¬ê¸°"""
        # ì‚¼ê°í˜• ê²½ê³  í‘œì‹œ
        points = np.array(
            [[x, y - h // 2], [x - w // 2, y + h // 2], [x + w // 2, y + h // 2]],
            np.int32,
        )

        cv2.fillPoly(self.frame_buffer, [points], color[:3])

        # ëŠë‚Œí‘œ
        cv2.putText(
            self.frame_buffer,
            "!",
            (x - 5, y + 5),
            cv2.FONT_HERSHEY_SIMPLEX,
            1.0,
            (0, 0, 0),
            2,
        )

    async def _draw_text_overlay(
        self, x: int, y: int, color: Tuple[int, int, int, int], text: str
    ):
        """í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸°"""
        if text:
            cv2.putText(
                self.frame_buffer,
                text,
                (x, y),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                color[:3],
                1,
            )

    async def _render_gaze_indicator(self, gaze_state: DriverGazeState):
        """ì‹œì„  ìœ„ì¹˜ í‘œì‹œ (ë””ë²„ê·¸ìš©)"""
        gaze_x = int(gaze_state.gaze_point[0] * self.screen_width)
        gaze_y = int(gaze_state.gaze_point[1] * self.screen_height)

        cv2.circle(self.frame_buffer, (gaze_x, gaze_y), 10, (255, 255, 255, 128), 2)

    def _adjust_color_for_brightness(
        self, color: Tuple[int, int, int, int]
    ) -> Tuple[int, int, int, int]:
        """ë°ê¸°ì— ë”°ë¥¸ ìƒ‰ìƒ ì¡°ì •"""
        # ì£¼ê°„/ì•¼ê°„ ëª¨ë“œì— ë”°ë¥¸ ìƒ‰ìƒ ì ì‘
        # ì‹¤ì œë¡œëŠ” ì£¼ë³€ ì¡°ë„ ì„¼ì„œ ë°ì´í„° í™œìš©
        r, g, b, a = color

        # ê°„ë‹¨í•œ ì•¼ê°„ ëª¨ë“œ ì‹œë®¬ë ˆì´ì…˜ (ì‹œê°„ ê¸°ë°˜)
        current_hour = time.localtime().tm_hour
        if 18 <= current_hour or current_hour <= 6:  # ì•¼ê°„
            # ë°ê¸° ì¦ê°€
            r = min(255, int(r * 1.3))
            g = min(255, int(g * 1.3))
            b = min(255, int(b * 1.3))

        return (r, g, b, a)

    def get_memory_stats(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í†µê³„"""
        buffer_size_mb = self.frame_buffer.nbytes / (1024 * 1024)

        return {
            "frame_buffer_size_mb": buffer_size_mb,
            "buffer_shape": self.frame_buffer.shape,
            "render_count": self._render_count,
            "last_cleanup": self._last_cleanup_time,
            "cleanup_interval": self._cleanup_interval,
        }
