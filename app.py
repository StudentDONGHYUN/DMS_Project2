# app.py - S-Class DMS System (ë¹„ë™ê¸° ì´ˆê¸°í™” ë¬¸ì œ í•´ê²°)

import cv2
import time
import asyncio
from pathlib import Path
from datetime import datetime
import logging
import threading
import queue
import numpy as np

# core ëª¨ë“ˆ
from core.definitions import CameraPosition
from core.state_manager import EnhancedStateManager

# integration ëª¨ë“ˆ - S-Class ì‹œìŠ¤í…œ
from integration.integrated_system import IntegratedDMSSystem, AnalysisSystemType

# systems ëª¨ë“ˆ
from systems.mediapipe_manager import AdvancedMediaPipeManager
from systems.performance import PerformanceOptimizer
from systems.personalization import PersonalizationEngine
from systems.dynamic import DynamicAnalysisEngine
from systems.backup import SensorBackupManager

# io_handler ëª¨ë“ˆ
from io_handler.video_input import VideoInputManager, MultiVideoCalibrationManager
from io_handler.ui import SClassAdvancedUIManager

# utils ëª¨ë“ˆ - ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸° í•¨ìˆ˜ë“¤
from utils.drawing import (
    draw_face_landmarks_on_image,
    draw_pose_landmarks_on_image,
    draw_hand_landmarks_on_image,
)
from utils.memory_monitor import MemoryMonitor, log_memory_usage

logger = logging.getLogger(__name__)

# ì´í•˜ app_backup_20250714_075833.pyì˜ ì „ì²´ ì½”ë“œ ë³µì› (DummyAnalysisEngine, IntegratedCallbackAdapter, DMSApp ë“±)


class DummyAnalysisEngine:
    def on_face_result(self, *args, **kwargs):
        pass

    def on_pose_result(self, *args, **kwargs):
        pass

    def on_hand_result(self, *args, **kwargs):
        pass

    def on_object_result(self, *args, **kwargs):
        pass

    frame_buffer = {}


class IntegratedCallbackAdapter:
    """
    í†µí•© ì½œë°± ì–´ëŒ‘í„° - MediaPipe ê²°ê³¼ë¥¼ IntegratedDMSSystemìœ¼ë¡œ ì „ë‹¬ (ìˆ˜ì •ëœ ë²„ì „)
    """

    def __init__(self, integrated_system, result_target=None):
        self.integrated_system = integrated_system
        self.result_target = result_target
        self.result_buffer = {}
        self.processing_lock = asyncio.Lock()
        self.last_processed_timestamp = 0
        self.last_integrated_results = self._get_fallback_results()
        self.RESULT_TIMEOUT = 0.5  # 500ms
        self.MAX_BUFFER_SIZE = 100  # ìµœëŒ€ ë²„í¼ í¬ê¸°
        self.buffer_cleanup_counter = 0
        logger.info("IntegratedCallbackAdapter (ìˆ˜ì •) ì´ˆê¸°í™” ì™„ë£Œ")

    async def on_face_result(self, result, timestamp=None, *args, **kwargs):
        await self._on_result("face", result, timestamp)

    async def on_pose_result(self, result, timestamp=None, *args, **kwargs):
        await self._on_result("pose", result, timestamp)

    async def on_hand_result(self, result, timestamp=None, *args, **kwargs):
        await self._on_result("hand", result, timestamp)

    async def on_object_result(self, result, timestamp=None, *args, **kwargs):
        await self._on_result("object", result, timestamp)

    async def _on_result(self, result_type, result, timestamp):
        ts = timestamp or int(time.time() * 1000)
        try:
            lock_acquisition_task = asyncio.create_task(self.processing_lock.acquire())
            try:
                await asyncio.wait_for(lock_acquisition_task, timeout=2.0)
                try:
                    if len(self.result_buffer) >= self.MAX_BUFFER_SIZE:
                        await self._emergency_buffer_cleanup()
                    if ts not in self.result_buffer:
                        self.result_buffer[ts] = {"timestamp": time.time()}
                    self.result_buffer[ts][result_type] = result
                    logger.debug(
                        f"Received {result_type} for ts {ts}. Buffer has keys: {list(self.result_buffer[ts].keys())}"
                    )
                    self.buffer_cleanup_counter += 1
                    if self.buffer_cleanup_counter % 10 == 0:
                        await self._prune_buffer()
                    if (
                        "face" in self.result_buffer[ts]
                        and "pose" in self.result_buffer[ts]
                    ):
                        await self._process_results(ts)
                finally:
                    self.processing_lock.release()
            except asyncio.TimeoutError:
                if not lock_acquisition_task.done():
                    lock_acquisition_task.cancel()
                    try:
                        await lock_acquisition_task
                    except asyncio.CancelledError:
                        pass
                raise
        except asyncio.TimeoutError:
            logger.warning(f"Lock íšë“ íƒ€ì„ì•„ì›ƒ - {result_type} ê²°ê³¼ ë¬´ì‹œë¨ (ts: {ts})")
        except Exception as e:
            logger.error(f"_on_result ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    async def _process_results(self, timestamp):
        if timestamp <= self.last_processed_timestamp:
            if timestamp in self.result_buffer:
                del self.result_buffer[timestamp]
            return
        results_to_process = self.result_buffer.pop(timestamp, None)
        if not results_to_process:
            return
        logger.info(f"Processing results for timestamp {timestamp}")
        try:
            integrated_results = await self.integrated_system.process_frame(
                results_to_process, timestamp
            )
            self.last_integrated_results = integrated_results
            self.last_processed_timestamp = timestamp
        except Exception as e:
            logger.error(f"í†µí•© ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            self.last_integrated_results = self._get_fallback_results()
        await self._prune_buffer()

    async def _prune_buffer(self):
        current_time = time.time()
        keys_to_delete = [
            ts
            for ts, data in self.result_buffer.items()
            if current_time - data["timestamp"] > self.RESULT_TIMEOUT
        ]
        for ts in keys_to_delete:
            logger.warning(f"Timeout for timestamp {ts}, removing from buffer.")
            del self.result_buffer[ts]

    async def _emergency_buffer_cleanup(self):
        if len(self.result_buffer) == 0:
            return
        logger.warning(f"ê¸´ê¸‰ ë²„í¼ ì •ë¦¬ ì‹¤í–‰ - í˜„ì¬ í¬ê¸°: {len(self.result_buffer)}")
        sorted_timestamps = sorted(self.result_buffer.keys())
        target_size = max(self.MAX_BUFFER_SIZE // 2, 1)
        current_size = len(self.result_buffer)
        if current_size <= target_size:
            logger.info(
                f"ë²„í¼ í¬ê¸°ê°€ ì´ë¯¸ ëª©í‘œ í¬ê¸° ì´í•˜ì…ë‹ˆë‹¤: {current_size} <= {target_size}"
            )
            return
        items_to_remove = current_size - target_size
        items_to_remove = min(items_to_remove, len(sorted_timestamps))
        removed_count = 0
        for i in range(items_to_remove):
            if i < len(sorted_timestamps):
                ts = sorted_timestamps[i]
                if ts in self.result_buffer:
                    del self.result_buffer[ts]
                    removed_count += 1
        logger.info(
            f"ê¸´ê¸‰ ì •ë¦¬ ì™„ë£Œ - ì œê±°ëœ í•­ëª©: {removed_count}, ìƒˆ í¬ê¸°: {len(self.result_buffer)}"
        )

    def get_latest_integrated_results(self):
        return self.last_integrated_results

    def _get_fallback_results(self):
        return {
            "fatigue_risk_score": 0.0,
            "distraction_risk_score": 0.0,
            "confidence_score": 0.0,
            "face_analysis": {},
            "pose_analysis": {},
            "hand_analysis": {},
            "object_analysis": {},
            "fusion_analysis": {},
            "system_health": "unknown",
        }


class DMSApp:
    """
    S-Class DMS ì• í”Œë¦¬ì¼€ì´ì…˜ - í†µí•© ì‹œìŠ¤í…œ ì—°ë™ ìˆ˜ì • ë²„ì „
    """

    def __init__(
        self,
        input_source=0,
        user_id: str = "default",
        camera_position: CameraPosition = CameraPosition.REARVIEW_MIRROR,
        enable_calibration: bool = True,
        is_same_driver: bool = True,
        system_type: AnalysisSystemType = AnalysisSystemType.STANDARD,
        use_legacy_engine: bool = False,
        sclass_features: dict = None,
        enable_performance_optimization: bool = True,
        edition: str = "RESEARCH",  # ğŸ†• ì¶”ê°€ëœ íŒŒë¼ë¯¸í„°
    ):
        logger.info("[ìˆ˜ì •] app_fixed.py: DMSApp.__init__ ì§„ì…")
        self.input_source = input_source
        self.user_id = user_id
        self.camera_position = camera_position
        self.enable_calibration = enable_calibration
        self.is_same_driver = is_same_driver
        self.system_type = system_type
        self.use_legacy_engine = use_legacy_engine
        self.sclass_features = sclass_features or {}
        self.edition = edition  # ğŸ†• edition ì €ì¥
        # ğŸ†• editionì— ë”°ë¥¸ ê¸°ëŠ¥ í™œì„±í™”/ë¹„í™œì„±í™” ì²˜ë¦¬
        self._configure_edition_features()

        self.running = False
        self.paused = False
        self.current_processed_frame = None
        self.initialization_completed = False
        self.safe_mode = False
        self.error_count = 0
        # GUI/ì„¤ì •ì—ì„œ enable_performance_optimization ê°’ì„ ë°›ì•„ì„œ ì „ë‹¬
        self.performance_monitor = PerformanceOptimizer(
            enable_optimization=enable_performance_optimization
        )
        self.personalization_engine = PersonalizationEngine(user_id)
        self.dynamic_analysis = DynamicAnalysisEngine()
        self.backup_manager = SensorBackupManager()
        self.calibration_manager = MultiVideoCalibrationManager(user_id)
        self.memory_monitor = MemoryMonitor(
            warning_threshold_mb=600,
            critical_threshold_mb=1000,
            cleanup_callback=self._perform_memory_cleanup,
        )
        self.ui_manager = SClassAdvancedUIManager()
        if isinstance(input_source, (list, tuple)) and len(input_source) > 1:
            self.calibration_manager.set_driver_continuity(self.is_same_driver)
        logger.info("[ìˆ˜ì •] S-Class ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    def _configure_edition_features(self):
        """ì—ë””ì…˜ì— ë”°ë¥¸ ê¸°ëŠ¥ ì„¤ì •"""
        logger.info(f"ì—ë””ì…˜ '{self.edition}'ì— ë”°ë¥¸ ê¸°ëŠ¥ ì„¤ì • ì¤‘...")

        if self.edition == "COMMUNITY":
            # ì»¤ë®¤ë‹ˆí‹° ì—ë””ì…˜: ê¸°ë³¸ ê¸°ëŠ¥ë§Œ
            self.sclass_features.update(
                {
                    "enable_rppg": False,
                    "enable_saccade": False,
                    "enable_spinal_analysis": False,
                    "enable_tremor_fft": False,
                    "enable_bayesian_prediction": False,
                    "enable_emotion_ai": False,
                    "enable_predictive_safety": False,
                    "enable_biometric_fusion": False,
                    "enable_adaptive_thresholds": False,
                }
            )

        elif self.edition == "PRO":
            # í”„ë¡œ ì—ë””ì…˜: S-Class ê³ ê¸‰ ê¸°ëŠ¥ í¬í•¨
            self.sclass_features.update(
                {
                    "enable_rppg": True,
                    "enable_saccade": True,
                    "enable_spinal_analysis": True,
                    "enable_tremor_fft": True,
                    "enable_bayesian_prediction": True,
                    "enable_emotion_ai": False,
                    "enable_predictive_safety": False,
                    "enable_biometric_fusion": False,
                    "enable_adaptive_thresholds": False,
                }
            )

        elif self.edition == "ENTERPRISE":
            # ì—”í„°í”„ë¼ì´ì¦ˆ ì—ë””ì…˜: Neural AI í¬í•¨
            self.sclass_features.update(
                {
                    "enable_rppg": True,
                    "enable_saccade": True,
                    "enable_spinal_analysis": True,
                    "enable_tremor_fft": True,
                    "enable_bayesian_prediction": True,
                    "enable_emotion_ai": True,
                    "enable_predictive_safety": True,
                    "enable_biometric_fusion": True,
                    "enable_adaptive_thresholds": True,
                }
            )

        elif self.edition == "RESEARCH":
            # ì—°êµ¬ìš© ì—ë””ì…˜: ëª¨ë“  ê¸°ëŠ¥ í™œì„±í™”
            self.sclass_features.update(
                {
                    "enable_rppg": True,
                    "enable_saccade": True,
                    "enable_spinal_analysis": True,
                    "enable_tremor_fft": True,
                    "enable_bayesian_prediction": True,
                    "enable_emotion_ai": True,
                    "enable_predictive_safety": True,
                    "enable_biometric_fusion": True,
                    "enable_adaptive_thresholds": True,
                }
            )

        logger.info(f"ì—ë””ì…˜ '{self.edition}' ê¸°ëŠ¥ ì„¤ì • ì™„ë£Œ: {self.sclass_features}")

    async def initialize(self) -> bool:
        logger.info("[ìˆ˜ì •] S-Class DMS ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
        try:
            # 1. ìƒíƒœ ê´€ë¦¬ì ì´ˆê¸°í™”
            self.state_manager = EnhancedStateManager(self.user_id)
            # 2. ë¹„ë””ì˜¤ ì…ë ¥ ì´ˆê¸°í™”
            self.video_input_manager = VideoInputManager(self.input_source)
            if not self.video_input_manager.initialize():
                logger.error("ë¹„ë””ì˜¤ ì…ë ¥ ì´ˆê¸°í™” ì‹¤íŒ¨")
                return False
            # 3. í†µí•© ë¶„ì„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (íŒŒë¼ë¯¸í„° ìˆ˜ì •)
            custom_config = {
                "user_id": self.user_id,
                "camera_position": self.camera_position,
                "enable_calibration": self.enable_calibration,
                "sclass_features": self.sclass_features,
            }
            self.integrated_system = IntegratedDMSSystem(
                system_type=self.system_type,
                custom_config=custom_config,
                use_legacy_engine=self.use_legacy_engine,
            )
            # 4. MediaPipe ë§¤ë‹ˆì € ì´ˆê¸°í™”
            self.mediapipe_manager = AdvancedMediaPipeManager(DummyAnalysisEngine())
            # 5. ì½œë°± ì–´ëŒ‘í„° ì—°ê²°
            self.callback_adapter = IntegratedCallbackAdapter(self.integrated_system)
            logger.info("[ìˆ˜ì •] S-Class DMS ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            self.initialization_completed = True
            return True
        except Exception as e:
            logger.error(f"S-Class DMS ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)
            return False

    def run(self):
        self.running = True
        logger.info("[ìˆ˜ì •] app.py: run ì§„ì…")
        import asyncio

        frame_queue = queue.Queue(maxsize=5)
        stop_event = threading.Event()

        def opencv_display_loop():
            logger.info("[ìˆ˜ì •] app.py: run - opencv_display_loop ì§„ì…")
            last_frame = None
            while not stop_event.is_set():
                try:
                    frame = frame_queue.get(timeout=0.1)
                    if frame is None:
                        break
                    last_frame = frame
                except queue.Empty:
                    pass
                if last_frame is not None:
                    try:
                        frame_to_show = (
                            cv2.UMat(last_frame)
                            if not isinstance(last_frame, cv2.UMat)
                            else last_frame
                        )
                    except Exception:
                        frame_to_show = last_frame
                    cv2.imshow("S-Class DMS v18+ - Research Integrated", frame_to_show)
                key = cv2.waitKey(1) & 0xFF
                if key == ord("q"):
                    stop_event.set()
                    break
                elif key == ord("s"):
                    if last_frame is not None:
                        filename = f"screenshot_{int(time.time())}.png"
                        try:
                            frame_to_save = (
                                cv2.UMat(last_frame)
                                if not isinstance(last_frame, cv2.UMat)
                                else last_frame
                            )
                        except Exception:
                            frame_to_save = last_frame
                        cv2.imwrite(filename, frame_to_save)
            cv2.destroyAllWindows()

        async def async_frame_producer():
            logger.info("[ìˆ˜ì •] app.py: run - async_frame_producer ì§„ì…")
            await self.initialize()
            logger.info("[ìˆ˜ì •] app.py: run - S-Class DMS ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            await asyncio.sleep(0.1)
            frame_count = 0
            last_perf_log_time = time.time()
            while not stop_event.is_set():
                frame = self.video_input_manager.get_frame()  # í•­ìƒ numpy
                if frame is None:
                    await asyncio.sleep(0.01)
                    continue
                frame_count += 1
                # GEMINI.md ì„±ëŠ¥ ìµœì í™”: MediaPipe ì²˜ë¦¬ ì „ writeable=False ì ìš©
                if hasattr(frame, "flags"):
                    frame.flags.writeable = False
                # MediaPipe ì²˜ë¦¬ (numpy)
                # (ì‹¤ì œ ë¶„ì„/ì‹œê°í™” íŒŒì´í”„ë¼ì¸ì— ë§ê²Œ ì•„ë˜ ë¼ì¸ ìˆ˜ì •)
                # ì˜ˆì‹œ: mediapipe_results = self.mediapipe_manager.process_frame(frame)
                # ì‹œê°í™”/ë Œë”ë§ ë‹¨ê³„ì—ì„œë§Œ UMat ë³€í™˜
                # ì˜ˆì‹œ: annotated_frame = draw_landmarks_on_image(cv2.UMat(frame), mediapipe_results)
                # annotated_frameì€ UMat
                # ì•„ë˜ëŠ” ê¸°ì¡´ annotated_frame ì²˜ë¦¬ ì˜ˆì‹œ
                annotated_frame = self._create_basic_info_overlay(
                    cv2.UMat(frame), frame_count, perf_stats=None
                )
                if annotated_frame is not None:
                    try:
                        frame_queue.put_nowait(annotated_frame)
                    except queue.Full:
                        try:
                            frame_queue.get_nowait()
                            frame_queue.put_nowait(annotated_frame)
                        except queue.Empty:
                            pass
                # --- [ì„±ëŠ¥ ìµœì í™” ìë™ í˜¸ì¶œ] ---
                if frame_count % 30 == 0:
                    processing_time = 0.0  # ì‹¤ì œ ì²˜ë¦¬ ì‹œê°„ ì¸¡ì • í•„ìš”ì‹œ ì¸¡ì •ê°’ ì‚¬ìš©
                    fps = 0.0
                    self.performance_monitor.log_performance(processing_time, fps)
                    self.mediapipe_manager.adjust_dynamic_resources()
                    self._perform_memory_cleanup()
                await asyncio.sleep(0.010)
            try:
                frame_queue.put(None, timeout=0.1)
            except queue.Full:
                pass

        display_thread = threading.Thread(target=opencv_display_loop)
        display_thread.start()
        asyncio.run(async_frame_producer())
        stop_event.set()
        display_thread.join()

    def _create_basic_info_overlay(self, frame, frame_count, perf_stats=None):
        # Ensure overlay is drawn on UMat
        try:
            annotated_frame = frame if isinstance(frame, cv2.UMat) else cv2.UMat(frame)
        except Exception:
            annotated_frame = frame
        height, width = (
            annotated_frame.get().shape[:2]
            if isinstance(annotated_frame, cv2.UMat)
            else annotated_frame.shape[:2]
        )
        # ì˜ˆì‹œ: í”„ë ˆì„ ë²ˆí˜¸ ë° FPS í‘œì‹œ
        cv2.putText(
            annotated_frame,
            f"Frame: {frame_count}",
            (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            1,
            (0, 255, 0),
            2,
        )
        if perf_stats is not None:
            fps = perf_stats.get("fps", 0.0)
            cv2.putText(
                annotated_frame,
                f"FPS: {fps:.1f}",
                (10, 60),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.8,
                (255, 255, 0),
                2,
            )
        return annotated_frame

    def _perform_memory_cleanup(self):
        logger.info("ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤í–‰")
